{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text Classification(Movie Review).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyONvosoPN9udMBM9JOpe7hS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SumathiGit/NLP-2/blob/main/Text_Classification(Movie_Review).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-GYwpbgDBGM2"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "BxYa0pzcBe6q",
        "outputId": "7611f8d7-1c8c-49a3-869c-9f696e77c065"
      },
      "source": [
        "df = pd.read_csv(\"moviereviews.tsv\", sep='\\t')\n",
        "df"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>neg</td>\n",
              "      <td>how do films like mouse hunt get into theatres...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>neg</td>\n",
              "      <td>some talented actresses are blessed with a dem...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>pos</td>\n",
              "      <td>this has been an extraordinary year for austra...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>pos</td>\n",
              "      <td>according to hollywood movies made in last few...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>neg</td>\n",
              "      <td>my first press screening of 1998 and already i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1995</th>\n",
              "      <td>pos</td>\n",
              "      <td>i like movies with albert brooks , and i reall...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1996</th>\n",
              "      <td>pos</td>\n",
              "      <td>it might surprise some to know that joel and e...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1997</th>\n",
              "      <td>pos</td>\n",
              "      <td>the verdict : spine-chilling drama from horror...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1998</th>\n",
              "      <td>pos</td>\n",
              "      <td>i want to correct what i wrote in a former ret...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1999</th>\n",
              "      <td>pos</td>\n",
              "      <td>a couple of months ago , when i first download...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2000 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     label                                             review\n",
              "0      neg  how do films like mouse hunt get into theatres...\n",
              "1      neg  some talented actresses are blessed with a dem...\n",
              "2      pos  this has been an extraordinary year for austra...\n",
              "3      pos  according to hollywood movies made in last few...\n",
              "4      neg  my first press screening of 1998 and already i...\n",
              "...    ...                                                ...\n",
              "1995   pos  i like movies with albert brooks , and i reall...\n",
              "1996   pos  it might surprise some to know that joel and e...\n",
              "1997   pos  the verdict : spine-chilling drama from horror...\n",
              "1998   pos  i want to correct what i wrote in a former ret...\n",
              "1999   pos  a couple of months ago , when i first download...\n",
              "\n",
              "[2000 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJOtpHzzKu22"
      },
      "source": [
        "#print(df['review'][2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_D60pRa9Be3_",
        "outputId": "1d2a8f94-c782-45fd-95d1-33f010a003aa"
      },
      "source": [
        "df.isnull().sum() #Seems like we have some missing reviews"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "label      0\n",
              "review    35\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3sHrG3kxBe2L"
      },
      "source": [
        "df.dropna(inplace=True)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LvJM1oUaBezX",
        "outputId": "095dff57-3acf-4921-b384-6aed260665f6"
      },
      "source": [
        "df.isnull().sum() "
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "label     0\n",
              "review    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "adB5W6G3Bewe",
        "outputId": "b332b191-0550-4be1-de76-47fb8f0dbd05"
      },
      "source": [
        "len(df)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1965"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "16ATUX2OBetz",
        "outputId": "fb234a9a-a653-48d0-e838-de3baae88b90"
      },
      "source": [
        "#Double check if there any other null values\n",
        "blanks = []  # start with an empty list\n",
        "\n",
        "for i,lb,rv in df.itertuples():  # iterate over the DataFrame\n",
        "    if type(rv)==str:            # avoid NaN values\n",
        "        if rv.isspace():         # test 'review' for whitespace\n",
        "            blanks.append(i)     # add matching index numbers to the list\n",
        "        \n",
        "print(len(blanks), 'blanks: ', blanks)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "27 blanks:  [57, 71, 147, 151, 283, 307, 313, 323, 343, 351, 427, 501, 633, 675, 815, 851, 977, 1079, 1299, 1455, 1493, 1525, 1531, 1763, 1851, 1905, 1993]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rijcb2SRBerF",
        "outputId": "2fbd2450-ec53-47e3-bc11-2e85386c3c8d"
      },
      "source": [
        "df.drop(blanks, inplace=True)\n",
        "\n",
        "len(df)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1938"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5b18HNjbBeoR",
        "outputId": "8577a441-55d5-4b6b-be4e-5753d9b706b5"
      },
      "source": [
        "df['label'].value_counts()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pos    969\n",
              "neg    969\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wc5f15ZrBel0"
      },
      "source": [
        "#Split the data into train & test sets:\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = df['review']\n",
        "y = df['label']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5Ey5I9qBeix"
      },
      "source": [
        "#Building a Pipeline to Vectorize the data, train and also fit the model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HaENcfH6Begb"
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "# NaÃ¯ve Bayes:(First PIPELINE)\n",
        "text_clf_nb = Pipeline([('tfidf', TfidfVectorizer()),\n",
        "                     ('clf', MultinomialNB()),\n",
        "])\n",
        "\n",
        "# Linear SVC:(SECOND PIPELINE)\n",
        "text_clf_lsvc = Pipeline([('tfidf', TfidfVectorizer()),\n",
        "                     ('clf', LinearSVC()),\n",
        "])"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yWlUFPFRBedm",
        "outputId": "9ac45e9a-2e78-4e09-c661-28a8131c6b87"
      },
      "source": [
        "#Passing thr training data into First pipeline\n",
        "text_clf_nb.fit(X_train, y_train)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('tfidf',\n",
              "                 TfidfVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 encoding='utf-8', input='content',\n",
              "                                 lowercase=True, max_df=1.0, max_features=None,\n",
              "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
              "                                 preprocessor=None, smooth_idf=True,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 sublinear_tf=False,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=None, use_idf=True,\n",
              "                                 vocabulary=None)),\n",
              "                ('clf',\n",
              "                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uq0w7Hb5BebJ"
      },
      "source": [
        "predictions = text_clf_nb.predict(X_test)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Rxby6GvBeYi",
        "outputId": "7274915c-8725-4220-a461-fa3e9e26fa0b"
      },
      "source": [
        "from sklearn import metrics\n",
        "print(metrics.confusion_matrix(y_test,predictions))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[287  21]\n",
            " [130 202]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y4jBQux8BeVk",
        "outputId": "6b2a2775-afdc-4c6f-d19d-f3946206c5d2"
      },
      "source": [
        "print(metrics.accuracy_score(y_test,predictions)) #WE got 76% accuracy"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7640625\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDafAOfEBeSj"
      },
      "source": [
        "#PAssing the training data into second pipeline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nk_B0qVlBeP5",
        "outputId": "fa73e2cf-5b1a-4309-d8d6-5bfa28e8ed65"
      },
      "source": [
        "text_clf_lsvc.fit(X_train, y_train)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('tfidf',\n",
              "                 TfidfVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 encoding='utf-8', input='content',\n",
              "                                 lowercase=True, max_df=1.0, max_features=None,\n",
              "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
              "                                 preprocessor=None, smooth_idf=True,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 sublinear_tf=False,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=None, use_idf=True,\n",
              "                                 vocabulary=None)),\n",
              "                ('clf',\n",
              "                 LinearSVC(C=1.0, class_weight=None, dual=True,\n",
              "                           fit_intercept=True, intercept_scaling=1,\n",
              "                           loss='squared_hinge', max_iter=1000,\n",
              "                           multi_class='ovr', penalty='l2', random_state=None,\n",
              "                           tol=0.0001, verbose=0))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5apFMJMUBeKj"
      },
      "source": [
        "predictions = text_clf_lsvc.predict(X_test)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6dP3Y9QNBeM7",
        "outputId": "f809631f-955b-4d67-8bae-3bbce7b893a6"
      },
      "source": [
        "print(metrics.confusion_matrix(y_test,predictions))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[259  49]\n",
            " [ 49 283]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VIS58SXABeIK",
        "outputId": "c9acec69-d4b8-48e6-9882-74738f6fbf47"
      },
      "source": [
        "print(metrics.accuracy_score(y_test,predictions)) #And now we got 84 % of accuracy"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.846875\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ggatkw0dBeFb"
      },
      "source": [
        "#Testing\n",
        "myreview = \"I saw this movie yesterday and guess what it's such an terrible movie ,The songs were awful, not good\""
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yERzx7hOBeC0",
        "outputId": "5b6ea45f-89be-4df8-f16b-fa52a9bdd5d2"
      },
      "source": [
        "print(text_clf_lsvc.predict([myreview]))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['neg']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2glZZVYaBeAF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDHVIusvI5Tc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVnwRs2ZI5Nw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ci9Gd4_eI5JV"
      },
      "source": [
        "\"\"\"Adding Stopwords to CountVectorizer\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DNoprTqiIsxs",
        "outputId": "96b3fd8d-ab4c-499b-dd21-4cf74758acf9"
      },
      "source": [
        "from sklearn.feature_extraction import text\n",
        "print(text.ENGLISH_STOP_WORDS)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "frozenset({'eleven', 'con', 'somehow', 'per', 'its', 'find', 'hereby', 'behind', 'few', 'here', 'now', 'side', 'there', 'very', 'wherever', 'eight', 'name', 'same', 'until', 'herself', 'even', 'whereby', 'nobody', 'he', 'without', 'almost', 'get', 'never', 'fifteen', 'indeed', 'co', 'hereupon', 'hereafter', 'therefore', 'whenever', 'another', 'up', 'ltd', 'mostly', 'others', 'nine', 'only', 'all', 'full', 'thus', 're', 'together', 'becomes', 'part', 'our', 'as', 'beside', 'keep', 'at', 'their', 'back', 'cant', 'put', 'onto', 'who', 'ourselves', 'whether', 'why', 'any', 'within', 'over', 'thereupon', 'de', 'ever', 'am', 'among', 'nowhere', 'own', 'throughout', 'two', 'the', 'every', 'detail', 'whom', 'towards', 'you', 'twelve', 'around', 'besides', 'when', 'give', 'next', 'while', 'forty', 'cry', 'on', 'me', 'from', 'your', 'be', 'after', 'itself', 'ie', 'but', 'too', 'therein', 'several', 'front', 'thru', 'they', 'along', 'etc', 'whole', 'us', 'please', 'was', 'yourselves', 'in', 'of', 'that', 'an', 'anyhow', 'could', 'each', 'not', 'thick', 'her', 'will', 'last', 'former', 'alone', 'it', 'those', 'has', 'top', 'can', 'somewhere', 'cannot', 'couldnt', 'either', 'had', 'by', 'became', 'sincere', 'under', 'show', 'thereby', 'nothing', 'out', 'some', 'would', 'less', 'take', 'about', 'done', 'both', 'a', 'this', 'three', 'meanwhile', 'everything', 'himself', 'most', 'thence', 'also', 'herein', 'four', 'whose', 'through', 'un', 'other', 'or', 'been', 'hasnt', 'beyond', 'themselves', 'whoever', 'latterly', 'no', 'otherwise', 'become', 'fill', 'elsewhere', 'are', 'system', 'move', 'much', 'see', 'one', 'bottom', 'mine', 'what', 'first', 'perhaps', 'describe', 'yours', 'because', 'for', 'noone', 'further', 'six', 'hers', 'anyway', 'everywhere', 'may', 'anything', 'down', 'i', 'thin', 'whatever', 'she', 'so', 'then', 'upon', 'do', 'none', 'amoungst', 'yet', 'being', 'than', 'sixty', 'thereafter', 'if', 'we', 'bill', 'against', 'since', 'however', 'neither', 'whence', 'between', 'due', 'whereas', 'except', 'hundred', 'interest', 'empty', 'least', 'well', 'go', 'sometime', 'anywhere', 'which', 'sometimes', 'twenty', 'else', 'whereafter', 'found', 'made', 'yourself', 'again', 'must', 'fifty', 'seemed', 'were', 'have', 'once', 'rather', 'many', 'serious', 'before', 'beforehand', 'off', 'latter', 'myself', 'amongst', 'across', 'where', 'these', 'call', 'more', 'nevertheless', 'often', 'amount', 'with', 'afterwards', 'although', 'whereupon', 'still', 'them', 'below', 'via', 'ours', 'whither', 'how', 'someone', 'nor', 'enough', 'formerly', 'moreover', 'eg', 'my', 'him', 'into', 'already', 'everyone', 'namely', 'hence', 'might', 'wherein', 'ten', 'mill', 'inc', 'becoming', 'above', 'seem', 'seems', 'should', 'fire', 'something', 'toward', 'is', 'to', 'though', 'five', 'his', 'such', 'and', 'third', 'during', 'seeming', 'anyone', 'always'})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dIXETwikIsjf"
      },
      "source": [
        "stopwords = ['a', 'about', 'an', 'and', 'are', 'as', 'at', 'be', 'been', 'but', 'by', 'can', \\\n",
        "             'even', 'ever', 'for', 'from', 'get', 'had', 'has', 'have', 'he', 'her', 'hers', 'his', \\\n",
        "             'how', 'i', 'if', 'in', 'into', 'is', 'it', 'its', 'just', 'me', 'my', 'of', 'on', 'or', \\\n",
        "             'see', 'seen', 'she', 'so', 'than', 'that', 'the', 'their', 'there', 'they', 'this', \\\n",
        "             'to', 'was', 'we', 'were', 'what', 'when', 'which', 'who', 'will', 'with', 'you']"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGYvvlykI0Dd"
      },
      "source": [
        "text_clf_lsvc1 = Pipeline([('tfidf', TfidfVectorizer(stop_words=stopwords)),\n",
        "                     ('clf', LinearSVC()),\n",
        "])"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B4GED5PbIz8D",
        "outputId": "4d4fce4d-29cb-4c95-9e33-1a55e14943bf"
      },
      "source": [
        "text_clf_lsvc1.fit(X_train, y_train)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('tfidf',\n",
              "                 TfidfVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 encoding='utf-8', input='content',\n",
              "                                 lowercase=True, max_df=1.0, max_features=None,\n",
              "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
              "                                 preprocessor=None, smooth_idf=True,\n",
              "                                 stop_words=['a', 'about', 'an', 'and', 'are',\n",
              "                                             'as', 'at', 'be', 'been', 'but',...\n",
              "                                             'how', 'i', 'if', 'in', 'into',\n",
              "                                             'is', ...],\n",
              "                                 strip_accents=None, sublinear_tf=False,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=None, use_idf=True,\n",
              "                                 vocabulary=None)),\n",
              "                ('clf',\n",
              "                 LinearSVC(C=1.0, class_weight=None, dual=True,\n",
              "                           fit_intercept=True, intercept_scaling=1,\n",
              "                           loss='squared_hinge', max_iter=1000,\n",
              "                           multi_class='ovr', penalty='l2', random_state=None,\n",
              "                           tol=0.0001, verbose=0))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dXwSAFyPIzzW"
      },
      "source": [
        "predictions = text_clf_lsvc1.predict(X_test)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1wgmQLCrJwR_",
        "outputId": "a4ef31f7-4e9f-4575-af43-2b51e10d4caa"
      },
      "source": [
        "print(metrics.confusion_matrix(y_test,predictions))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[256  52]\n",
            " [ 48 284]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "smHlH40YJzPx",
        "outputId": "33018925-55e2-4706-eb1b-99f846e9c160"
      },
      "source": [
        "print(metrics.accuracy_score(y_test,predictions))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.84375\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NoK7LuChJ-V7",
        "outputId": "cf6d8409-cd0e-4fa3-d915-9d74c4a464dd"
      },
      "source": [
        "print(text_clf_lsvc1.predict([myreview]))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['neg']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8QFOFJXrKVC2"
      },
      "source": [
        "myrev = \"A movie I really wanted to love was terrible. \\\n",
        "I'm sure the producers had the best intentions, but the execution was lacking.\""
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PJgwh1cAKU_t",
        "outputId": "90ea9498-80ef-4dbe-ee21-eb209c272c8d"
      },
      "source": [
        "print(text_clf_lsvc1.predict([myrev]))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['neg']\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}